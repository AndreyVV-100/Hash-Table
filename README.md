# Исследование хеш-таблиц

## Введение

В данной работе рассматриваются алгоритмы хеширования и способы её оптимизации хеш-таблицы. Поэтому работа разделена на 2 соответствующие части. Итак, приступим.

## 1. Алгоритмы хеширования

### 0.0) Требования к алгоритму

Хеш-таблица - структура данных, работающая с данными вида "ключ - значение". В нашем случае и ключ, и значение - строковые данные. Для быстрого доступа по ключу используется хеширование - сопоставление ключу какого-то числа, по которому производится доступ в таблицу. Т.к. хеш может получится довольно большим, сама пара ключ-значение будет храниться в ячейке [hash % size].

Вполне возможно, что значение hash % size для нескольких пар к.-з. совпадёт. Поэтому во время поиска по таблице придётся перебирать все ключи, соответствующие данной ячейке (они хранятся методом цепочек), и сравнивать с данным. Эта операция занимает наибольшее время, затраты на неё нужно оптимизировать.

Из этих соображений очевидно, что главное требование к алгоритму подсчёта контрольной суммы (хеша) - равномерное распределение по всем ячейкам таблицы.

### 0.1) Методика измерения

Для этой работы мы написали хеш-таблицу, в которой реализована функция заполнения из файла. На вход будет подаваться небольшой англо-русский словарь (порядка 6500 слов). Размер таблицы, будет сжат с рекомендуемых 1,5 элемента на ячейку до 10-15 для того, чтобы большинство ячеек было заполнено.

Коллизии, как было сказано ранее, будут решаться методом цепочек. Поэтому в массиве будут храниться указатели на первый элемент списка, а в самих элементах (структурах для хранения пары к.-з.) - на следующий. С кодом можно ознакомиться в папке "Lab 1".

Далее с помощью библиотеки matplotlib строится график, где по оси абцисс откладывается номер ячейки, а ординат - количество элементов в ячейке. По нему можно судить о равномерности распределения хеш-функции. Для лучших алгоритмов будет найдена дисперсия.

<!--- ToDo: Подсветка от Git, вставка картинок через команды md-->

### 1) Const Hash

Функция всегда возвращает одно и то же, заранее определённое значение. Это самая простая функция, время которой, к тому же, не зависит от размера ключа. Но она неэффективна, у неё вряд ли найдётся какое-либо практическое применение.

<img src = "Lab 1/ScreenShots/1. Const.png" height = 80>
<center>
<img src = "Lab 1/Graphics/1. Const.png" height = 300>
</center>

### 2) Len Hash

Функция возвращает длину ключа. Имеет узкий диапазон значений (ключи имеют длину от 2 до 30 символов) и плохое распределение. Очевидно, она не подходит для больших таблиц.

<img src = "Lab 1/ScreenShots/2. Len.png" height = 100>
<center>
<img src = "Lab 1/Graphics/2. Len.png" height = 300>
</center>

### 3) Sum Hash

Функция возвращает сумму байт символов ключа, представленных в кодировке UTF-8 (т.к. ключ - английское слово, то эта сумма совпадает с суммой ASCII-кодов символов). Распределение плохое, т.к. числовые значения букв лежат от 97 до 122, и в значениях, кратных этим, есть очевидные пики. Возможно, при длине таблицы не более 26 этот алгоритм имел бы применение, но тогда сама таблица вряд ли является эффективной структурой для хранения данных.

<img src = "Lab 1/ScreenShots/3. Sum.png" height = 240>
<center>
<img src = "Lab 1/Graphics/3. Sum.png" height = 300>
</center>

### 4) SumLen Hash

Функция возвращает результат 3-го алгоритма, поделённого на результат 2-го. По своей сути является средним значением символа, поэтому имеет такое плохое распределение.

<img src = "Lab 1/ScreenShots/4. SumLen.png" height = 160>
<center>
<img src = "Lab 1/Graphics/4. SumLen.png" height = 300>
</center>

### 5) FirstChar

Возвращает значение первого символа. Своими проблемами очень схожа на предыдущую, хотя и имеет "более ровное" распределение.

<img src = "Lab 1/ScreenShots/5. FirstChar.png" height = 100>
<center>
<img src = "Lab 1/Graphics/5. FirstChar.png" height = 300>
</center>

### 6) ROL

Эта функция производит посимвольный проход: посчитанный для предыдущих букв ключа хеш циклически сдвигается влево, после чего к нему прибавляется значение текущего символа. Функция имеет хорошее распределение, её дисперсия (среднеквадратическое отклонение) D = 41,1.

<img src = "Lab 1/ScreenShots/6. ROL.png" height = 260>
<center>
<img src = "Lab 1/Graphics/6. ROL.png" height = 300>
</center>

### 7) ROR

Алгоритм аналогичен предыдущему, только сдвиг теперь производится вправо. D = 28,6.

<img src = "Lab 1/ScreenShots/7. ROR.png" height = 260>
<center>
<img src = "Lab 1/Graphics/7. ROR.png" height = 300>
</center>

### 8) CRC

Алгоритм работает как "деление в столбик", только деление заменено на побитовый XOR. В нашем случае делимым выступает ключ, а делителем - определённая константа. Более строго это объясняется как деление многочленов друг на друга, но тут мы не будет вдаваться в подробности, т.к. это долго и трудно для понимания. D = 17,1.

<img src = "Lab 1/ScreenShots/8. CRC32.png" height = 380>
<center>
<img src = "Lab 1/Graphics/8. CRC32.png" height = 300>
</center>

### 9) Выводы

Очевидно, что лучше всего показали себя последние 3 функции, теперь сравним их. Но тут придётся немножко заглянуть в будущее. Далее, в рамках второй части работы, они будут переписаны на языке assembly, а размер таблицы увеличен до рекомендуемого. И там результаты измерений получились следующие:

    CRC: D = 1,5  ROL: D = 2,5  ROR: D = 5,7

Таким образом, CRC превосходит циклические алгоритмы, но кто лучше: ROL или ROL - определить сложно. Наше мнение - ROL лучше, так как показал себя лучше в ситуации, более приближенной к реальности. Более того, т.к. при индексации берётся остаток от деления на размер таблицы, некоторое число старших разрядов "отбрасывается", поэтому эффективнее (в теории) должен быть алгоритм, который "чаще изменяет младшие разряды хеша, а не старшие" (извините за слишком вольное объяснение), т.е. ROL.

## 2. Ускорение работы хеш-таблицы

### 0) Общий подход к работе

Прежде всего мы реализовали функцию поиска ключа по таблице (напомню, что коллизии в ней решаются методом цепочек), после чего будем запускать поиск большого количества (100000) элементов. В нашем случае элемент для поиска будет выбираться случайно из списка: "cat", "dog", "fox", "monkey", "elephant", "chel", "fucker", "slave". Это сделано для исключения возможных случайных оптимизаций, при этом количество инструкций будет колебаться около некого среднего значения. Но это не повлияет на принимаемые решения, т.к. флуктуации составляют около 100 тысяч инструкций, а оптимизации будут делать изменения на порядок больше. Далее "бутылочное горлышко" таблицы будет устраняться и находиться новое до тех пор, пока оптимизация не станет слишком трудоёмкой, а результаты мизерными. При этом функции, используемые в main и не являющиеся членами-функциями класса HashTable, оптимизироваться не будут, так как мы считаем это пользовательским кодом, к которому мы не имеем доступ.

Программа будет собираться в 2-х конфигурациях:

Без оптимизации:

    all: main.cpp HashTable.cpp HashFunctions.cpp
        g++ main.cpp HashTable.cpp HashFunctions.cpp -Wall
        valgrind --tool=callgrind ./a.out

С оптимизацей -O3:

    all: main.cpp HashTable.cpp HashFunctions.cpp
        g++ main.cpp HashTable.cpp HashFunctions.cpp -Wall -O3
        valgrind --tool=callgrind ./a.out

Данные о работе программы будет собирать утилита callgrind, после чего в KCacheGrind строится граф, в котором отражена основная информация о работе программы (функции и количество инструкций, которое выражено либо в абсолютном значении, либо в процентах от общего количества).

Стоит отметить, что мы пробовали другие средства анализа: perf и gprof. Но первый давал информацию о системных вызовах, при этом о собственных функциях программы ничего не было известно. А второй, напротив, говорил только о них, при этом значения были очень приблизительными. Утилита VTune от Intel, которая могла бы стать отличной заменой им, требовала 30 ГБ свободного места, а на рабочей установке его было всего 24 ГБ. Поэтому выбор пал на золотую середину между ними: callgrind. Стоит отметить, что, возможно, просто мы не смогли найти достаточно информации о настройке других. Если у вас есть таковая, свяжитесь, пожалуйста, с нами.

### 1) Начальные характеристики

Вот результаты тестов неоптимизированной программы (см. спойлер, далее всё будет помещаться в спойлерах):

<details>
<summary> Спойлер 1, в инструкциях, без оптимизаций </summary>

#### __CRC__

<img src = "Lab 2/Graphics/No optimization/instructions/1crc.png">

#### __ROL__

<img src = "Lab 2/Graphics/No optimization/instructions/1rol.png">

#### __ROR__

<img src = "Lab 2/Graphics/No optimization/instructions/1ror.png">
</details>

<details>
<summary> Спойлер 1, в процентах, без оптимизаций </summary>

#### __CRC__

<img src = "Lab 2/Graphics/No optimization/percent/1crc.png">

#### __ROL__

<img src = "Lab 2/Graphics/No optimization/percent/1rol.png">

#### __ROR__

<img src = "Lab 2/Graphics/No optimization/percent/1ror.png">
</details>

<details>
<summary> Спойлер 1, в инструкциях, с оптимизациями </summary>

#### __CRC__

<img src = "Lab 2/Graphics/-O3/instructions/1crc.png">

#### __ROL__

<img src = "Lab 2/Graphics/-O3/instructions/1rol.png">

#### __ROR__

<img src = "Lab 2/Graphics/-O3/instructions/1ror.png">
</details>

<details>
<summary> Спойлер 1, в процентах, с оптимизациями </summary>

#### __CRC__

<img src = "Lab 2/Graphics/-O3/percent/1crc.png">

#### __ROL__

<img src = "Lab 2/Graphics/-O3/percent/1rol.png">

#### __ROR__

<img src = "Lab 2/Graphics/-O3/percent/1ror.png">
</details>

### 2) Улучшение 1

Первое, что бросается в глаза во время анализа программы - чрезмерно большое количество инструкций в алгоритме CRC. Без -O3 количество инструкций CRC в 12 раз отличается от ROR и ROL. При этом CRC c -O3 и без него тоже сильно отличаются: в 3 раза. Но на данный момент только CRC занимает много инструкций в процентном соотношении, поэтому переписать его можно позже, вместе со всеми остальными алгоритмами.

Заметим, что во время исполнения программ на алгоритмах ROL и ROR довольно большое время занимает сравнение строк (__strcmp_avx2): 23% и 20%, при этом сами функции занимают 6% и 7% соответственно. Это означает, что после нахождения хеша происходит долгих поиск элемента в ячейке, т.к. самих элементов в ней слишком много. Эту проблему можно решить, если уменьшить их количество, увеличив размер таблицы. Итак, изменим размер таблицы до рекомендуемых 1,5 элемента на ячейку. Мы получили такие результаты: 

<details>
<summary> Спойлер 2, в инструкциях, без оптимизаций </summary>

#### __CRC__

<img src = "Lab 2/Graphics/No optimization/instructions/2crc.png">

#### __ROL__

<img src = "Lab 2/Graphics/No optimization/instructions/2rol.png">

#### __ROR__

<img src = "Lab 2/Graphics/No optimization/instructions/2ror.png">
</details>

<details>
<summary> Спойлер 2, в процентах, без оптимизаций </summary>

#### __CRC__

<img src = "Lab 2/Graphics/No optimization/percent/2crc.png">

#### __ROL__

<img src = "Lab 2/Graphics/No optimization/percent/2rol.png">

#### __ROR__

<img src = "Lab 2/Graphics/No optimization/percent/2ror.png">
</details>

<details>
<summary> Спойлер 2, в инструкциях, с оптимизациями </summary>

#### __CRC__

<img src = "Lab 2/Graphics/-O3/instructions/2crc.png">

#### __ROL__

<img src = "Lab 2/Graphics/-O3/instructions/2rol.png">

#### __ROR__

<img src = "Lab 2/Graphics/-O3/instructions/2ror.png">
</details>

<details>
<summary> Спойлер 2, в процентах, с оптимизациями </summary>

#### __CRC__

<img src = "Lab 2/Graphics/-O3/percent/2crc.png">

#### __ROL__

<img src = "Lab 2/Graphics/-O3/percent/2rol.png">

#### __ROR__

<img src = "Lab 2/Graphics/-O3/percent/2ror.png">
</details>

Итог (в инструкциях, -O3):

    CRC: 24,5М -> 3,4М
    ROL: 29,8М -> 7,1М
    ROR: 24,7М -> 8,7М

Очевидно, что это небольшое изменение привело к значительным улучшениям.

### 3) Улучшение 2

Стоит отметить, что CRC, благодаря лучшему распределению, меньшее количество раз обращается к strcmp. Соответственно, если переписать его, то он станет быстрее ROL и ROR.

Для этого можно использовать функции языка ассемблера: ror (циклический сдвиг вправо), rol (влево), crc. Есть несколько путей их использования:

1) Использовать ассемблерные вставки в циклах функций, остальное остаётся по-прежнему.

2) В силу специфики ключа (малый размер), его можно поместить в переменную типа __m256_epi8, тогда операции сравнения ключей будут быстрее, но при этом хеш-таблица станет занимать больше места и требовать дополнительных затрат при переводе из строкового типа (если это не было сделано заранее).

3) Написать функции хеширования на assembly полностью. Это будет эффективно для сравнения, но strcmp останется тот же. Но он написан с помощью инструкций avx2.

Нами было принято решение написать именно третий вариант, т.к. выгода от второго варианта не совсем очевидна на данном этапе, но при этом его реализация потребует больших затрат. Возможно, после будет написан второй и будет возможность сравнить его с третьим. Плюсы первого перед последним же не очевидны, поэтому мы напишем последний, т.к. у него, предположительно, больше быстродействие.

Вот все функции, написанные на asm-е:

<img src = "Lab 2/Screenshots/crc.png" height = 660>

<img src = "Lab 2/Screenshots/rol.png" height = 410>

<img src = "Lab 2/Screenshots/ror.png" height = 410>

Функции.
